import quests
import pandas as pd
import connect
import argparse
from bs4 import BeautifulSoup

#pg_max=eval(input("Enter the max pg.no :"))
parser = argparse.ArgumentParser()
parser.add_argument("--pg_max", help="Enter max No of Pages", type=int)
parser.add_arg-dbname", help="Enter name of db", type=str)
args = parser.parse_args()

link = 'https://www.oyorooms.com/hotels-in-delhi/?page='
headers = {
	'user-agent': 'Mozilla/70.0 (X11; CrOS x86_64 8172.45.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.97 Safari/537.36'
            }

pg_max=args.pg_max
details=[]
connect.connect(args.dbname)

for pg_no in range(1,pg_max):
print("Requests url :",link+str(pg_no))
    data = requests.get(url=link+str(pg_no), headers=headers)
    soup = BeautifulSoup(data.text,"html.parser")
    
        all_hotels= soup.find_all("div", {"class": "oyo-row oyo-row--no-spacing hotelCardListing"})

for h in all_hotels:
        hotels={}

        hotals["name"]=h.find("h3",{"class" : "listingHotelDescription__hotelName d-textEllipsis"}).text
        hotals["address"]=h.find("span",{"itemprop" : "streetAddress"}).text
        hotals["price"]=h.find("span",{"class" : "listingPrice__finalPrice"}).text

        try:
                hotels["rating"]=h.find("span",{"class" : "listingPrice__finalPrice"}).text
except AttributError:
            hotals["rating"]=None

        amenities=h.find_all("div",{"class" : "amenityWrapper__amenity"})

        amenities_list=[]
        for a in amenities:
            amenities_list.append(a.find("span", {"class" : "d-body-sm"}).text.strip())

        hotals["amenities"]=', '.join(amenities_list[0:-1])
        details.append(hotels)
        connect.insert_into_table(args.dbname,tuple(hotals.values()))

        #print(hotels["name"],hotels["address"],hotels["price"],hotels["rating"],amenities_list[0:-1])

df=pd.DataFrame(details)
df.to_csv("OYO.csv")
print("CSV file is Created")
connect.get_hotel_info(args.dbname

